{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGay5leVy1KV"
      },
      "source": [
        "# Execution (Local)\n",
        "\n",
        "**Root folder:** /home/bravo-z6/Dropbox/_Exp/_cvd/dino_cov/\n",
        "\n",
        "**Run Jupyter in local:**\n",
        "\n",
        "```\n",
        "jupyter notebook \\\n",
        "  --NotebookApp.allow_origin='https://colab.research.google.com' \\\n",
        "  --port=8888 \\\n",
        "  --NotebookApp.port_retries=0\n",
        "```\n",
        "\n",
        "**Connect to local execution env**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpLm2zBpQUdR"
      },
      "source": [
        "# **## Training DINO ##**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IUkCaRiZJ7A"
      },
      "source": [
        "### Tiny Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLx9YauCiAxw"
      },
      "outputs": [],
      "source": [
        "#!python -m torch.distributed.launch --nproc_per_node=8 main_dino.py --arch vit_small --data_path /path/to/imagenet/train --output_dir /path/to/saving_dir\n",
        "\n",
        "### Data \n",
        "#--data_path Data/breast_data/d2/dino_tr/ \\\n",
        "\n",
        "import os\n",
        "\n",
        "data_dir = \"cvd_data/train/dino/\"\n",
        "output_dir = \"Results/tiny_cvd/\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "!python main_dino.py --arch vit_tiny --batch_size_per_gpu 32 \\\n",
        "                     --epochs 301 \\\n",
        "                     --teacher_temp 0.07 --warmup_teacher_temp_epochs 30 \\\n",
        "                     --norm_last_layer true \\\n",
        "                     --data_path $data_dir \\\n",
        "                     --output_dir $output_dir \\\n",
        "                     --num-channels 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0v3bcUAiAxq"
      },
      "source": [
        "### Small Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0SrHxt6ZJ7D"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "data_dir = \"cvd_data/train/dino/\"\n",
        "output_dir = \"Results/tiny_cvd/\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "!python main_dino.py --arch vit_small \\\n",
        "                     --momentum_teacher 0.9995 \\\n",
        "                     --batch_size_per_gpu 30 \\\n",
        "                     --data_path cvd_data/train/dino/ \\\n",
        "                     --output_dir Results/small_cvd/ \\\n",
        "                     --epochs 101 \\\n",
        "                     --num-channels 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yx7VcMU4vpH"
      },
      "source": [
        "# **## Visualizing and Storing attention maps ##**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I41ixNOQai3"
      },
      "source": [
        "## --- Visualize Attention Maps ---\n",
        "\n",
        "```\n",
        "!python visualize_attention.py --arch vit_small --pretrained_weights Results/checkpoint0080.pth --patch_size 16 \\\n",
        "                                  --image_path Data/breast_data/d2/test/Mri_10_R1_IM-1683-0597.tiff \\\n",
        "                                  --output_dir Attention_maps/\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97NuuWgybA1H"
      },
      "source": [
        "### Tiny Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POz7QogZbA1I"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "eval_path = \"cvd_data/test/dino/1/\" #dino_ts\n",
        "out_path = \"Attention_maps/tiny_cvd/\"\n",
        "os.makedirs(out_path, exist_ok=True)\n",
        "\n",
        "model_chk = \"Results/tiny_cvd/checkpoint0300.pth\"\n",
        "att_names = [\"attn-head0.png\",\"attn-head1.png\",\"attn-head2.png\",\"img.png\"]\n",
        "\n",
        "for image in os.listdir(eval_path)[:10]: \n",
        "    full_image = eval_path + image\n",
        "    ##\n",
        "    !python visualize_attention.py --arch vit_tiny --pretrained_weights $model_chk --patch_size 16 \\\n",
        "                                  --image_path $full_image \\\n",
        "                                  --output_dir $out_path \\\n",
        "                                  --num-channels 1\n",
        "    ##\n",
        "    for map_name in att_names: \n",
        "        os.rename(out_path + map_name, out_path + os.path.splitext(image)[0] + \"_\" + map_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rGGwrzBjPhY"
      },
      "source": [
        "## --- Store Attention Maps ---\n",
        "\n",
        "```\n",
        "!python store_attention.py --arch vit_small --pretrained_weights Results/checkpoint0080.pth --patch_size 16 \\\n",
        "                                  --image_path Data/breast_data/d2/test/Mri_10_R1_IM-1683-0597.tiff \\\n",
        "                                  --output_dir Attention_maps/\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BNjABa0z-uS"
      },
      "source": [
        "### Tiny Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-Hi78EWz-uU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "eval_path = \"Data/breast_data/d0/dino_ts/test0/\"#dino_ts\n",
        "out_path = \"Attention_maps/tiny_d0_gs/arrays/\"\n",
        "model_chk = \"Results/tiny_d0_gs/checkpoint0300.pth\"\n",
        "\n",
        "att_names = [\"attn-heads.npy\"] #,\"img.png\"\n",
        "\n",
        "os.makedirs(out_path, exist_ok=True)\n",
        "for image in os.listdir(eval_path): \n",
        "    full_image = eval_path + image\n",
        "    ##\n",
        "    !python store_attention.py --arch vit_tiny --pretrained_weights $model_chk --patch_size 16 \\\n",
        "                                  --image_path $full_image \\\n",
        "                                  --output_dir $out_path\n",
        "    ##\n",
        "    for map_name in att_names: \n",
        "        os.rename(out_path + map_name, out_path + os.path.splitext(image)[0] + \"_\" + map_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ezIQCSa5SrJ"
      },
      "source": [
        "# **## Extracting features from DINO ##**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrLli9wEJmD-"
      },
      "source": [
        "## --- Reorganize features ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOXSA0wUJkmA",
        "outputId": "025b32b2-e845-4d0b-febc-265be9747fb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reorganizing test files.... \n",
            "This might take a while\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████████████████████████████| 870/870 [00:22<00:00, 38.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reorganizing train files.... \n",
            "This might take a while\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████████████████████| 6862/6862 [04:11<00:00, 27.26it/s]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm \n",
        "\n",
        "train_meta = pd.read_csv(\"cvd_data/train_setup_2.csv\")\n",
        "test_meta = pd.read_csv(\"cvd_data/test_setup_2.csv\")\n",
        "\n",
        "# Reorder test files \n",
        "print (\"Reorganizing test files.... \\nThis might take a while\")\n",
        "for i in tqdm(range(len(test_meta)), ncols=100):\n",
        "  #\n",
        "  src = \"cvd_data/test/FULL/{0}\".format(test_meta.name.iloc[i])\n",
        "  dst = \"cvd_data/test/dino/{0}/{1}\".format(test_meta.label.iloc[i], test_meta.name.iloc[i])\n",
        "  os.makedirs(\"cvd_data/test/dino/\" + str(test_meta.label.iloc[i]), exist_ok=True)\n",
        "  os.system(\"cp {0} {1}\".format(src, dst))\n",
        "  #print(\"cp {0} {1}\".format(src, dst))\n",
        "\n",
        "\n",
        "# Reorder train files \n",
        "print (\"Reorganizing train files.... \\nThis might take a while\")\n",
        "for i in tqdm(range(len(train_meta)), ncols=100):\n",
        "  #\n",
        "  src = \"cvd_data/train/FULL/{0}\".format(train_meta.name.iloc[i])\n",
        "  dst = \"cvd_data/train/dino/{0}/{1}\".format(train_meta.label.iloc[i], train_meta.name.iloc[i])\n",
        "  os.makedirs(\"cvd_data/train/dino/\" + str(train_meta.label.iloc[i]), exist_ok=True)\n",
        "  os.system(\"cp {0} {1}\".format(src, dst))\n",
        "  #print(\"cp {0} {1}\".format(src, dst))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtNS-ET6Dl7U"
      },
      "source": [
        "## --- Extract DINO features ---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebiaGi9EbrUz"
      },
      "source": [
        "### Tiny run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVmobR3EbrU0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "train_path = \"cvd_data/train/dino/\"\n",
        "eval_path  = \"cvd_data/test/dino/\"\n",
        "#eval_path = \"Data/breast_data/d0/dino_ts/test0/\"#dino_ts\n",
        "out_path = \"Features/tiny_cvd/\"\n",
        "model_chk = \"Results/tiny_cvd/checkpoint0300.pth\"\n",
        "\n",
        "\n",
        "!python extract_features.py --arch vit_tiny --imsize 480 --multiscale 0 \\\n",
        "                            --train_data_path $train_path --test_data_path $eval_path \\\n",
        "                            --pretrained_weights $model_chk \\\n",
        "                            --output_dir $out_path --num-channels 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IykC7kR7ZLHP"
      },
      "source": [
        "## --- Find labels after extracting features ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm \n",
        "\n",
        "train_meta = pd.read_csv(\"cvd_data/train_setup_2.csv\")\n",
        "test_meta = pd.read_csv(\"cvd_data/test_setup_2.csv\")\n",
        "\n",
        "train_feat = pd.read_csv(\"Features/small_cvd_s/train_features.csv\")\n",
        "test_feat = pd.read_csv(\"Features/small_cvd_s/test_features.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1A9NA76ZLHZ",
        "outputId": "025b32b2-e845-4d0b-febc-265be9747fb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reorganizing test files.... \n",
            "This might take a while\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████████████████████████████| 870/870 [00:22<00:00, 38.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reorganizing train files.... \n",
            "This might take a while\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████████████████████| 6862/6862 [04:11<00:00, 27.26it/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Reorder test files \n",
        "print (\"Reorganizing test files.... \\nThis might take a while\")\n",
        "for i in tqdm(range(len(test_meta)), ncols=100):\n",
        "  #\n",
        "  src = \"cvd_data/test/FULL/{0}\".format(test_meta.name.iloc[i])\n",
        "  dst = \"cvd_data/test/dino/{0}/{1}\".format(test_meta.label.iloc[i], test_meta.name.iloc[i])\n",
        "  os.makedirs(\"cvd_data/test/dino/\" + str(test_meta.label.iloc[i]), exist_ok=True)\n",
        "  os.system(\"cp {0} {1}\".format(src, dst))\n",
        "  #print(\"cp {0} {1}\".format(src, dst))\n",
        "\n",
        "\n",
        "# Reorder train files \n",
        "print (\"Reorganizing train files.... \\nThis might take a while\")\n",
        "for i in tqdm(range(len(train_meta)), ncols=100):\n",
        "  #\n",
        "  src = \"cvd_data/train/FULL/{0}\".format(train_meta.name.iloc[i])\n",
        "  dst = \"cvd_data/train/dino/{0}/{1}\".format(train_meta.label.iloc[i], train_meta.name.iloc[i])\n",
        "  os.makedirs(\"cvd_data/train/dino/\" + str(train_meta.label.iloc[i]), exist_ok=True)\n",
        "  os.system(\"cp {0} {1}\".format(src, dst))\n",
        "  #print(\"cp {0} {1}\".format(src, dst))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y007CeuZ5dkb"
      },
      "source": [
        "# **## Dimensionality reduction on features ##**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPyS2spPWQVW"
      },
      "source": [
        "## --- Visualize with t-SNE ---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VM4JqsYUSMeC"
      },
      "source": [
        "### Tiny run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jm5sArTWnTXv",
        "outputId": "8c04d56e-7abe-4333-8be6-9995c28e983b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-06-08 19:04:26,079 [INFO ]  Start data loading.... This might take a while.\n",
            "2022-06-08 19:04:26,095 [INFO ]  Data with shape (6852, 192) successfully loaded! \n",
            "===================\n",
            "2022-06-08 19:04:26,095 [INFO ]  Starting t-SNE with params: \n",
            "This might take a while....\n",
            "/home/bravo-z6/venvs/dino_env/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
            "  warnings.warn(\n",
            "[t-SNE] Computing 121 nearest neighbors...\n",
            "[t-SNE] Indexed 6852 samples in 0.002s...\n",
            "[t-SNE] Computed neighbors for 6852 samples in 0.867s...\n",
            "[t-SNE] Computed conditional probabilities for sample 1000 / 6852\n",
            "[t-SNE] Computed conditional probabilities for sample 2000 / 6852\n",
            "[t-SNE] Computed conditional probabilities for sample 3000 / 6852\n",
            "[t-SNE] Computed conditional probabilities for sample 4000 / 6852\n",
            "[t-SNE] Computed conditional probabilities for sample 5000 / 6852\n",
            "[t-SNE] Computed conditional probabilities for sample 6000 / 6852\n",
            "[t-SNE] Computed conditional probabilities for sample 6852 / 6852\n",
            "[t-SNE] Mean sigma: 0.000000\n",
            "/home/bravo-z6/venvs/dino_env/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:982: FutureWarning: The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
            "  warnings.warn(\n",
            "[t-SNE] KL divergence after 250 iterations with early exaggeration: 30.271259\n",
            "[t-SNE] KL divergence after 2000 iterations: -0.170928\n",
            "2022-06-08 19:05:49,938 [INFO ]  t-SNE done! \n",
            "===================\n",
            "2022-06-08 19:05:49,939 [INFO ]  Results saved! \n",
            "===================\n",
            "2022-06-08 19:05:49,939 [INFO ]  Visualizing.... \n",
            "2022-06-08 19:05:50,589 [INFO ]  Figure saved as: Features/tiny_cvd/tsne/tr_class_tsne.png\n",
            "===================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data = \"Features/tiny_cvd/\"\n",
        "subset = \"train\"\n",
        "#subset = \"test\"\n",
        "\n",
        "mode = \"class\"\n",
        "#mode = \"birads\"\n",
        "\n",
        "abrv = \"tr_\" if subset == \"train\" else \"ts_\"\n",
        "\n",
        "if   mode == \"class\":\n",
        "  out_i = data + \"tsne/\" + abrv + \"class_tsne.png\"\n",
        "  out_r = data + \"tsne/\" + abrv + \"class_tsne.npy\"\n",
        "elif mode == \"birads\": \n",
        "  out_i = \"Features/tiny/tsne/\" + abrv + \"brd_tsne.png\"\n",
        "  out_r = \"Features/tiny/tsne/\" + abrv + \"brd_tsne.npy\"\n",
        "elif mode == \"ID\": \n",
        "  out_i = \"Features/tiny/tsne/\" + abrv + \"id_tsne.png\"\n",
        "  out_r = \"Features/tiny/tsne/\" + abrv + \"id_tsne.npy\"\n",
        "\n",
        "!python visualize_tSNE.py --data_path $data --subset $subset \\\n",
        "                          --num_samples -1 --out_image $out_i --out_results $out_r \\\n",
        "                          --n_components 2 --mode $mode \\\n",
        "                          --noise 50 --n_iter 2000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrHLWpA-W1f0"
      },
      "source": [
        "### Small run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKrhz25BW1f1",
        "outputId": "8c04d56e-7abe-4333-8be6-9995c28e983b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-06-08 19:04:26,079 [INFO ]  Start data loading.... This might take a while.\n",
            "2022-06-08 19:04:26,095 [INFO ]  Data with shape (6852, 192) successfully loaded! \n",
            "===================\n",
            "2022-06-08 19:04:26,095 [INFO ]  Starting t-SNE with params: \n",
            "This might take a while....\n",
            "/home/bravo-z6/venvs/dino_env/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
            "  warnings.warn(\n",
            "[t-SNE] Computing 121 nearest neighbors...\n",
            "[t-SNE] Indexed 6852 samples in 0.002s...\n",
            "[t-SNE] Computed neighbors for 6852 samples in 0.867s...\n",
            "[t-SNE] Computed conditional probabilities for sample 1000 / 6852\n",
            "[t-SNE] Computed conditional probabilities for sample 2000 / 6852\n",
            "[t-SNE] Computed conditional probabilities for sample 3000 / 6852\n",
            "[t-SNE] Computed conditional probabilities for sample 4000 / 6852\n",
            "[t-SNE] Computed conditional probabilities for sample 5000 / 6852\n",
            "[t-SNE] Computed conditional probabilities for sample 6000 / 6852\n",
            "[t-SNE] Computed conditional probabilities for sample 6852 / 6852\n",
            "[t-SNE] Mean sigma: 0.000000\n",
            "/home/bravo-z6/venvs/dino_env/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:982: FutureWarning: The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
            "  warnings.warn(\n",
            "[t-SNE] KL divergence after 250 iterations with early exaggeration: 30.271259\n",
            "[t-SNE] KL divergence after 2000 iterations: -0.170928\n",
            "2022-06-08 19:05:49,938 [INFO ]  t-SNE done! \n",
            "===================\n",
            "2022-06-08 19:05:49,939 [INFO ]  Results saved! \n",
            "===================\n",
            "2022-06-08 19:05:49,939 [INFO ]  Visualizing.... \n",
            "2022-06-08 19:05:50,589 [INFO ]  Figure saved as: Features/tiny_cvd/tsne/tr_class_tsne.png\n",
            "===================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data = \"Features/tiny_cvd/\"\n",
        "subset = \"train\"\n",
        "#subset = \"test\"\n",
        "\n",
        "mode = \"class\"\n",
        "#mode = \"birads\"\n",
        "\n",
        "abrv = \"tr_\" if subset == \"train\" else \"ts_\"\n",
        "\n",
        "if   mode == \"class\":\n",
        "  out_i = data + \"tsne/\" + abrv + \"class_tsne.png\"\n",
        "  out_r = data + \"tsne/\" + abrv + \"class_tsne.npy\"\n",
        "elif mode == \"birads\": \n",
        "  out_i = \"Features/tiny/tsne/\" + abrv + \"brd_tsne.png\"\n",
        "  out_r = \"Features/tiny/tsne/\" + abrv + \"brd_tsne.npy\"\n",
        "elif mode == \"ID\": \n",
        "  out_i = \"Features/tiny/tsne/\" + abrv + \"id_tsne.png\"\n",
        "  out_r = \"Features/tiny/tsne/\" + abrv + \"id_tsne.npy\"\n",
        "\n",
        "!python visualize_tSNE.py --data_path $data --subset $subset \\\n",
        "                          --num_samples -1 --out_image $out_i --out_results $out_r \\\n",
        "                          --n_components 2 --mode $mode \\\n",
        "                          --noise 50 --n_iter 2000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgQt_ehzC-Iw"
      },
      "source": [
        "## --- Visualize with UMAP ---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsnPRr0bDBfC"
      },
      "source": [
        "### Tiny run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImiNlNayDBfD",
        "outputId": "8883363d-c385-4909-af57-f0fabe0a1226"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-06-08 19:24:05,203 [INFO ]  Start data loading.... This might take a while.\r\n",
            "2022-06-08 19:24:05,213 [INFO ]  Data with shape (870, 192) successfully loaded! \r\n",
            "===================\r\n",
            "2022-06-08 19:24:05,213 [INFO ]  Starting UMAP with params: \r\n",
            "This might take a while....\n",
            "2022-06-08 19:24:49,403 [INFO ]  UMAP done! \n",
            "===================\n",
            "2022-06-08 19:24:49,403 [INFO ]  Results saved! \n",
            "===================\n",
            "2022-06-08 19:24:49,403 [INFO ]  Visualizing.... \n",
            "2022-06-08 19:24:49,859 [INFO ]  Figure saved as: Features/tiny_cvd/umap/ts_class_umap.png\n",
            "===================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data = \"Features/tiny_cvd/\"\n",
        "subset = \"train\"\n",
        "subset = \"test\"\n",
        "\n",
        "mode = \"class\"\n",
        "\n",
        "abrv = \"tr_\" if subset == \"train\" else \"ts_\"\n",
        "\n",
        "if   mode == \"class\":\n",
        "  out_i = data + \"umap/\" + abrv + \"class_umap.png\"\n",
        "  out_r = data + \"umap/\" + abrv + \"class_umap.npy\"\n",
        "elif mode == \"birads\": \n",
        "  out_i = \"Features/tiny/umap/\" + abrv + \"brd_umap.png\"\n",
        "  out_r = \"Features/tiny/umap/\" + abrv + \"brd_umap.npy\"\n",
        "elif mode == \"ID\": \n",
        "  out_i = \"Features/tiny/umap/\" + abrv + \"id_umap.png\"\n",
        "  out_r = \"Features/tiny/umap/\" + abrv + \"id_umap.npy\"\n",
        "\n",
        "!python visualize_umap.py --data_path $data --subset $subset \\\n",
        "                          --num_samples -1 --out_image $out_i --out_results $out_r \\\n",
        "                          --n_components 2 --n_neighbors 50 --metric euclidean \\\n",
        "                          --mode $mode --noise 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pheGraR05qSb"
      },
      "source": [
        "# **## Classification on DINO features ##**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GU_BUN6DxqV"
      },
      "source": [
        "## --- Conditioning data ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnKqwLgyDucp",
        "outputId": "f985bbe5-33d3-4fb6-f643-76f24ccb147a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================================\n",
            "Subset: train, Sequence: d0, split: birads \n",
            "\n",
            "Input_path: Data/breast_data/d0/train/, \n",
            "Output_path: Data/breast_data/d0/tr_birads/ \n",
            "\n",
            "Files copied: 757 \n",
            "Done!\n",
            "========================================\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "seq = \"d0\"\n",
        "subset = \"train\"  # val\n",
        "split = \"birads\" # acr\n",
        "\n",
        "#input_path = \"Data/breast_data/d2/test/\"\n",
        "#output_path = \"Data/breast_data/d2/ts_\" + split + \"/\"\n",
        "\n",
        "input_path = \"Data/breast_data/\" + seq + \"/train/\"\n",
        "output_path = \"Data/breast_data/\" + seq + \"/tr_\" + split + \"/\"\n",
        "\n",
        "meta_file = \"Data/breast_data/metadata/\" + subset + \"_acr_birads.csv\"\n",
        "\n",
        "meta = pd.read_csv(meta_file)\n",
        "files_copied = 0\n",
        "\n",
        "for file_ in os.listdir(input_path): \n",
        "  #\n",
        "  _, pat, roi, name_img = file_.split(\"_\")\n",
        "  indexes = meta.index[(meta[\"patient\"] == \"Breast_Mri_\" + str(pat)) & (meta['ROI'] == str(roi))].tolist()\n",
        "  \n",
        "  if indexes != []: \n",
        "    files_copied += 1\n",
        "    found = meta.iloc[indexes[0]][split]\n",
        "    os.makedirs(os.path.join(output_path, str(found)), exist_ok = True)\n",
        "    os.system (\"cp {0} {1}\".format(os.path.join(input_path, file_), os.path.join(output_path, str(found), file_)))\n",
        "    #print (\"cp {0} {1}\".format(os.path.join(input_path, file_), os.path.join(output_path, str(found), file_)))\n",
        "\n",
        "print (\"========================================\")\n",
        "print (\"Subset: {0}, Sequence: {1}, split: {2} \\n\".format(subset, seq, split))\n",
        "print (\"Input_path: {0}, \\nOutput_path: {1} \\n\".format(input_path, output_path))\n",
        "print (\"Files copied: {0} \\nDone!\".format(files_copied))\n",
        "print (\"========================================\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAdb5Gb-2lSr"
      },
      "source": [
        "## --- kNN ---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0wm6LJrXmV8"
      },
      "source": [
        "### per ACR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AR7r9F9d2okf",
        "outputId": "a50b9977-2ea3-498d-fb50-34dc1ced747a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/bravo-z6/venvs/dino_env/lib/python3.8/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated\r\n",
            "and will be removed in future. Use torchrun.\r\n",
            "Note that --use_env is set by default in torchrun.\r\n",
            "If your script expects `--local_rank` argument to be set, please\r\n",
            "change it to read from `os.environ['LOCAL_RANK']` instead. See \r\n",
            "https://pytorch.org/docs/stable/distributed.html#launch-utility for \r\n",
            "further instructions\r\n",
            "\r\n",
            "  warnings.warn(\n",
            "| distributed init (rank 0): env://\n",
            "/usr/bin/nvidia-modprobe: unrecognized option: \"-s\"\n",
            "\n",
            "ERROR: Invalid commandline, please run `/usr/bin/nvidia-modprobe --help` for\n",
            "       usage information.\n",
            "\n",
            "/usr/bin/nvidia-modprobe: unrecognized option: \"-s\"\n",
            "\n",
            "ERROR: Invalid commandline, please run `/usr/bin/nvidia-modprobe --help` for\n",
            "       usage information.\n",
            "\n",
            "fatal: no es un repositorio git ( o ningún padre en el punto de montado /)\n",
            "Parando en el límite del sistema de archivos (GIT_DISCOVERY_ACROSS_FILESYSTEM no establecido).\n",
            "git:\n",
            "  sha: N/A, status: clean, branch: N/A\n",
            "\n",
            "arch: vit_tiny\n",
            "batch_size_per_gpu: 128\n",
            "checkpoint_key: teacher\n",
            "data_path: cvd_data/\n",
            "dist_url: env://\n",
            "dump_features: Features/dump/\n",
            "gpu: 0\n",
            "load_features: Features/dump/\n",
            "local_rank: 0\n",
            "nb_knn: [10, 20, 100, 200]\n",
            "num_channels: 1\n",
            "num_workers: 10\n",
            "patch_size: 16\n",
            "pretrained_weights: Results/tiny_cvd/checkpoint0300.pth\n",
            "rank: 0\n",
            "temperature: 0.07\n",
            "train_path: train/dino/\n",
            "use_cuda: True\n",
            "val_path: test/dino/\n",
            "world_size: 1\n",
            "Loading features.....\n",
            "Features are ready!\n",
            "Start the k-NN classification.\n",
            "10-NN classifier result: Top1: 79.08045977011494, Top5: 95.63218390804597\n",
            "20-NN classifier result: Top1: 79.88505747126437, Top5: 97.47126436781609\n",
            "100-NN classifier result: Top1: 80.11494252873563, Top5: 99.08045977011494\n",
            "200-NN classifier result: Top1: 78.96551724137932, Top5: 99.77011494252874\n"
          ]
        }
      ],
      "source": [
        "model_chk = \"Results/tiny_cvd/checkpoint0300.pth\"\n",
        "data_path = \"cvd_data/\"\n",
        "split = \"class\"\n",
        "\n",
        "train_set = \"train/dino/\"; \n",
        "val_set = \"test/dino/\"\n",
        "dump_features = \"Features/dump/\"\n",
        "load_features = \"Features/dump/\"\n",
        "patch_size = 16\n",
        "\n",
        "!python -m torch.distributed.launch --nproc_per_node=1 eval_knn.py \\\n",
        "                --arch vit_tiny --patch_size $patch_size \\\n",
        "                --pretrained_weights $model_chk \\\n",
        "                --checkpoint_key teacher --num_channels 1 \\\n",
        "                --data_path $data_path \\\n",
        "                --load_features $load_features \\\n",
        "                --dump_features $dump_features \\\n",
        "                --train_path $train_set --val_path $val_set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLYn3k_0Yegr"
      },
      "source": [
        "### per BIRADS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84HxpenSYeg0",
        "outputId": "353321c9-d532-4da6-c1cc-34a801259fe1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/ruben-kubuntu/venvs/dino_env/lib/python3.8/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated\r\n",
            "and will be removed in future. Use torchrun.\r\n",
            "Note that --use_env is set by default in torchrun.\r\n",
            "If your script expects `--local_rank` argument to be set, please\r\n",
            "change it to read from `os.environ['LOCAL_RANK']` instead. See \r\n",
            "https://pytorch.org/docs/stable/distributed.html#launch-utility for \r\n",
            "further instructions\r\n",
            "\r\n",
            "  warnings.warn(\n",
            "| distributed init (rank 0): env://\n",
            "git:\n",
            "  sha: cb711401860da580817918b9167ed73e3eef3dcf, status: has uncommited changes, branch: main\n",
            "\n",
            "arch: vit_tiny\n",
            "batch_size_per_gpu: 128\n",
            "checkpoint_key: teacher\n",
            "data_path: Data/breast_data/d0/\n",
            "dist_url: env://\n",
            "dump_features: Features/dump/\n",
            "gpu: 0\n",
            "load_features: None\n",
            "local_rank: 0\n",
            "nb_knn: [10, 20, 100, 200]\n",
            "num_channels: 1\n",
            "num_workers: 10\n",
            "patch_size: 16\n",
            "pretrained_weights: Results/tiny_d0_gs/checkpoint0300.pth\n",
            "rank: 0\n",
            "temperature: 0.07\n",
            "train_path: tr_birads/\n",
            "use_cuda: True\n",
            "val_path: ts_birads/\n",
            "world_size: 1\n",
            "/home/ruben-kubuntu/venvs/dino_env/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Data loaded with 758 train and 236 val imgs.\n",
            "Creating ViT with channel size: 1\n",
            "Model vit_tiny 16x16 built.\n",
            "Take key teacher in provided checkpoint dict\n",
            "Pretrained weights found at Results/tiny_d0_gs/checkpoint0300.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['head.mlp.0.weight', 'head.mlp.0.bias', 'head.mlp.2.weight', 'head.mlp.2.bias', 'head.mlp.4.weight', 'head.mlp.4.bias', 'head.last_layer.weight_g', 'head.last_layer.weight_v'])\n",
            "Extracting features for train set...\n",
            "Storing features into tensor of shape torch.Size([758, 192])\n",
            "  [0/6]  eta: 0:00:06    time: 1.102030  data: 1.041601  max mem: 324\n",
            "  [5/6]  eta: 0:00:00    time: 0.230441  data: 0.173648  max mem: 325\n",
            " Total time: 0:00:01 (0.241429 s / it)\n",
            "Extracting features for val set...\n",
            "Storing features into tensor of shape torch.Size([236, 192])\n",
            "  [0/2]  eta: 0:00:01    time: 0.792298  data: 0.782095  max mem: 325\n",
            "  [1/2]  eta: 0:00:00    time: 0.425463  data: 0.391070  max mem: 325\n",
            " Total time: 0:00:00 (0.457681 s / it)\n",
            "Features are ready!\n",
            "Start the k-NN classification.\n",
            "10-NN classifier result: Top1: 34.32203389830509, Top5: 61.440677966101696\n",
            "20-NN classifier result: Top1: 36.86440677966102, Top5: 76.27118644067797\n",
            "100-NN classifier result: Top1: 25.847457627118644, Top5: 99.15254237288136\n",
            "200-NN classifier result: Top1: 35.16949152542373, Top5: 99.15254237288136\n"
          ]
        }
      ],
      "source": [
        "model_chk = \"Results/tiny_d0_gs/checkpoint0300.pth\"\n",
        "data_path = \"Data/breast_data/d0/\"\n",
        "split = \"birads\"\n",
        "\n",
        "train_set = \"tr_\" + split + \"/\"; val_set = \"ts_\" + split + \"/\"\n",
        "dump_features = \"Features/dump/\"\n",
        "load_features = None #\"Features/dump/\"\n",
        "patch_size = 16\n",
        "\n",
        "!python -m torch.distributed.launch --nproc_per_node=1 eval_knn.py \\\n",
        "                --arch vit_tiny --patch_size $patch_size \\\n",
        "                --pretrained_weights $model_chk \\\n",
        "                --checkpoint_key teacher --num_channels 1 \\\n",
        "                --data_path $data_path \\\n",
        "                --load_features $load_features \\\n",
        "                --dump_features $dump_features \\\n",
        "                --train_path $train_set --val_path $val_set"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "6yx7VcMU4vpH",
        "8rGGwrzBjPhY",
        "DrLli9wEJmD-",
        "jtNS-ET6Dl7U",
        "y007CeuZ5dkb",
        "pheGraR05qSb",
        "9GU_BUN6DxqV",
        "wAdb5Gb-2lSr",
        "k0wm6LJrXmV8",
        "WLYn3k_0Yegr"
      ],
      "name": "dino_cvd.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
